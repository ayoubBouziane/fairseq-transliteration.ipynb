{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fairseq-transliteration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "R88wyQO2PPHE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# seq2seq with Fairseq\n",
        "\n",
        "This notebook uses Fairseq and PyTorch to train a sequence-to-sequence model.\n",
        "\n",
        "Note you must turn on GPU to use Fairseq!\n",
        "\n",
        "> *Edit > Notebook settings > Hardware accelerator: GPU*\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Yyowwr6LPX-z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ]
    },
    {
      "metadata": {
        "id": "PcyS5mCjPObY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "ec2bb522-634e-4bb1-cbcc-9e16658cf2e5"
      },
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!rm -rf fairseq\n",
        "!git clone https://github.com/deeplanguageclass/fairseq.git\n",
        "%cd fairseq\n",
        "!ls\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'fairseq'...\n",
            "remote: Counting objects: 2189, done.\u001b[K\n",
            "remote: Total 2189 (delta 0), reused 0 (delta 0), pack-reused 2189\u001b[K\n",
            "Receiving objects: 100% (2189/2189), 2.75 MiB | 32.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1613/1613), done.\n",
            "/content/fairseq\n",
            "CONTRIBUTING.md       fairseq.gif\t\tPATENTS\t\t  scripts\n",
            "distributed_train.py  generate.py\t\tpreprocess.py\t  setup.py\n",
            "eval_lm.py\t      interactive.py\t\tREADME.md\t  tests\n",
            "examples\t      LICENSE\t\t\trequirements.txt  train.py\n",
            "fairseq\t\t      multiprocessing_train.py\tscore.py\n",
            "Collecting cffi (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/c0/47db8f624f3e4e2f3f27be03a93379d1ba16a1450a7b1aacfa0366e2c0dd/cffi-1.11.5-cp36-cp36m-manylinux1_x86_64.whl (421kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.14.5)\n",
            "Collecting torch (from -r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 29kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x58522000 @  0x7fe8c2ff21c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting tqdm (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e6/19dfaff08fcbee7f3453e5b537e65a8364f1945f921a36d08be1e2ff3475/tqdm-4.24.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 12.1MB/s \n",
            "\u001b[?25hCollecting pycparser (from cffi->-r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/2d/aad7f16146f4197a11f8e91fb81df177adcc2073d36a17b1491fd09df6ed/pycparser-2.18.tar.gz (245kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 21.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycparser\n",
            "  Running setup.py bdist_wheel for pycparser ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/c0/a1/27/5ba234bd77ea5a290cbf6d675259ec52293193467a12ef1f46\n",
            "Successfully built pycparser\n",
            "Installing collected packages: pycparser, cffi, torch, tqdm\n",
            "Successfully installed cffi-1.11.5 pycparser-2.18 torch-0.4.1 tqdm-4.24.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mdmKcCwFMqlV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2519
        },
        "outputId": "f0e61c37-e55f-442a-b7bf-39e403d0f3b3"
      },
      "cell_type": "code",
      "source": [
        "!python setup.py build\n",
        "!python setup.py develop"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build\r\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/__init__.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/average_checkpoints.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/build_sym_alignment.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "creating build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/progress_bar.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/utils.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/multiprocessing_pdb.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/__init__.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/tokenizer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/trainer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/meters.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/bleu.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/fp16_trainer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/options.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/distributed_utils.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "creating build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/utils.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_sequence_generator.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/__init__.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_train.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_data_utils.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_convtbc.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_utils.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_label_smoothing.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_average_checkpoints.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_dictionary.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_binaries.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_sequence_scorer.py -> build/lib.linux-x86_64-3.6/tests\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/lstm.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fconv.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/transformer.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/nag.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/adam.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "running build_ext\n",
            "building 'fairseq.libbleu' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/fairseq\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib/libbleu\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fdebug-prefix-map=/build/python3.6-sXpGnM/python3.6-3.6.3=. -specs=/usr/share/dpkg/no-pie-compile.specs -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o -std=c++11\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fdebug-prefix-map=/build/python3.6-sXpGnM/python3.6-3.6.3=. -specs=/usr/share/dpkg/no-pie-compile.specs -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -std=c++11\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -specs=/usr/share/dpkg/no-pie-link.specs -Wl,-z,relro -Wl,-Bsymbolic-functions -specs=/usr/share/dpkg/no-pie-link.specs -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.6-sXpGnM/python3.6-3.6.3=. -specs=/usr/share/dpkg/no-pie-compile.specs -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so\n",
            "running develop\n",
            "running egg_info\n",
            "creating fairseq.egg-info\n",
            "writing fairseq.egg-info/PKG-INFO\n",
            "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
            "writing requirements to fairseq.egg-info/requires.txt\n",
            "writing top-level names to fairseq.egg-info/top_level.txt\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "reading manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so -> fairseq\n",
            "Creating /usr/local/lib/python3.6/dist-packages/fairseq.egg-link (link to .)\n",
            "Adding fairseq 0.5.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/fairseq\n",
            "Processing dependencies for fairseq==0.5.0\n",
            "Searching for tqdm==4.24.0\n",
            "Best match: tqdm 4.24.0\n",
            "Adding tqdm 4.24.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==0.4.1\n",
            "Best match: torch 0.4.1\n",
            "Adding torch 0.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.14.5\n",
            "Best match: numpy 1.14.5\n",
            "Adding numpy 1.14.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cffi==1.11.5\n",
            "Best match: cffi 1.11.5\n",
            "Adding cffi 1.11.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pycparser==2.18\n",
            "Best match: pycparser 2.18\n",
            "Adding pycparser 2.18 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for fairseq==0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3u_dRkrJO9fC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "4yDn86nIs2cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2468
        },
        "outputId": "d7d4917e-a57d-4d00-bee2-5a04b9ad5496"
      },
      "cell_type": "code",
      "source": [
        "%cd examples/translation/\n",
        "!bash prepare-iwslt14.sh\n",
        "%cd ../..\n",
        "\n",
        "!python preprocess.py --source-lang de --target-lang en \\\n",
        "  --trainpref examples/translation/iwslt14.tokenized.de-en/train \\\n",
        "  --validpref examples/translation/iwslt14.tokenized.de-en/valid \\\n",
        "  --testpref examples/translation/iwslt14.tokenized.de-en/test \\\n",
        "  --destdir data-bin/iwslt14.tokenized.de-en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fairseq/examples/translation\n",
            "Cloning Moses github repository (for tokenization scripts)...\n",
            "Cloning into 'mosesdecoder'...\n",
            "remote: Counting objects: 147104, done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 147104 (delta 0), reused 2 (delta 0), pack-reused 147098\u001b[K\n",
            "Receiving objects: 100% (147104/147104), 129.65 MiB | 21.17 MiB/s, done.\n",
            "Resolving deltas: 100% (113696/113696), done.\n",
            "Cloning Subword NMT repository (for BPE pre-processing)...\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Counting objects: 455, done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 455 (delta 18), reused 18 (delta 9), pack-reused 420\u001b[K\n",
            "Receiving objects: 100% (455/455), 204.70 KiB | 12.79 MiB/s, done.\n",
            "Resolving deltas: 100% (262/262), done.\n",
            "Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n",
            "--2018-08-16 11:18:05--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n",
            "Resolving wit3.fbk.eu (wit3.fbk.eu)... 217.77.80.8\n",
            "Connecting to wit3.fbk.eu (wit3.fbk.eu)|217.77.80.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19982877 (19M) [application/x-gzip]\n",
            "Saving to: ‘de-en.tgz’\n",
            "\n",
            "de-en.tgz           100%[===================>]  19.06M  5.58MB/s    in 4.4s    \n",
            "\n",
            "2018-08-16 11:18:10 (4.34 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\n",
            "\n",
            "Data successfully downloaded.\n",
            "de-en/\n",
            "de-en/IWSLT14.TED.dev2010.de-en.de.xml\n",
            "de-en/IWSLT14.TED.dev2010.de-en.en.xml\n",
            "de-en/IWSLT14.TED.tst2010.de-en.de.xml\n",
            "de-en/IWSLT14.TED.tst2010.de-en.en.xml\n",
            "de-en/IWSLT14.TED.tst2011.de-en.de.xml\n",
            "de-en/IWSLT14.TED.tst2011.de-en.en.xml\n",
            "de-en/IWSLT14.TED.tst2012.de-en.de.xml\n",
            "de-en/IWSLT14.TED.tst2012.de-en.en.xml\n",
            "de-en/IWSLT14.TEDX.dev2012.de-en.de.xml\n",
            "de-en/IWSLT14.TEDX.dev2012.de-en.en.xml\n",
            "de-en/README\n",
            "de-en/train.en\n",
            "de-en/train.tags.de-en.de\n",
            "de-en/train.tags.de-en.en\n",
            "pre-processing train data...\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "clean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n",
            "..........(100000).......\n",
            "Input sentences: 174443  Output sentences:  167497\n",
            "pre-processing valid/test data...\n",
            "orig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "creating train, valid, test...\n",
            "learn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n",
            "subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "apply_bpe.py to train.de...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to valid.de...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to test.de...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to train.en...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to valid.en...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to test.en...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "/content/fairseq\n",
            "Namespace(alignfile=None, destdir='data-bin/iwslt14.tokenized.de-en', joined_dictionary=False, nwordssrc=-1, nwordstgt=-1, only_source=False, output_format='binary', padding_factor=8, source_lang='de', srcdict=None, target_lang='en', testpref='examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, thresholdsrc=0, thresholdtgt=0, trainpref='examples/translation/iwslt14.tokenized.de-en/train', validpref='examples/translation/iwslt14.tokenized.de-en/valid')\n",
            "| [de] Dictionary: 127 types\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AcNYbXT2O4Tc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "KZtPXjH5QJ__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14d79596-6244-4f1f-cdde-e9a4c8b79e73"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p checkpoints/fconv\n",
        "!CUDA_VISIBLE_DEVICES=0 python train.py data-bin/iwslt14.tokenized.de-en \\\n",
        "  --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
        "  --arch fconv_iwslt_de_en --save-dir checkpoints/fconv --skip-invalid-size-inputs-valid-test"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'train.py': [Errno 2] No such file or directory\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SAFrx--fPeNr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ]
    },
    {
      "metadata": {
        "id": "V0DVOzfePiYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459173
        },
        "outputId": "38d9a974-a90c-4550-87af-edef52b55e46"
      },
      "cell_type": "code",
      "source": [
        "!python generate.py data-bin/iwslt14.tokenized.de-en \\\n",
        "  --path checkpoints/fconv/checkpoint_best.pt \\\n",
        "  --batch-size 128 --beam 5"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}