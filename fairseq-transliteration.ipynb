{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fairseq-transliteration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "R88wyQO2PPHE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# seq2seq with Fairseq\n",
        "\n",
        "This notebook uses Fairseq and PyTorch to train a sequence-to-sequence model.\n",
        "\n",
        "Note you must turn on GPU to use Fairseq!\n",
        "\n",
        "> *Edit > Notebook settings > Hardware accelerator: GPU*\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Yyowwr6LPX-z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ]
    },
    {
      "metadata": {
        "id": "PcyS5mCjPObY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!rm -rf fairseq\n",
        "!git clone https://github.com/deeplanguageclass/fairseq.git\n",
        "%cd fairseq\n",
        "!ls\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mdmKcCwFMqlV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2519
        },
        "outputId": "f0e61c37-e55f-442a-b7bf-39e403d0f3b3"
      },
      "cell_type": "code",
      "source": [
        "!python setup.py build\n",
        "!python setup.py develop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build\r\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/__init__.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/average_checkpoints.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "copying scripts/build_sym_alignment.py -> build/lib.linux-x86_64-3.6/scripts\n",
            "creating build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/progress_bar.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/utils.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/multiprocessing_pdb.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/__init__.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/tokenizer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/trainer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/meters.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/bleu.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/fp16_trainer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/options.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/distributed_utils.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-3.6/fairseq\n",
            "creating build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/utils.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_sequence_generator.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/__init__.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_train.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_data_utils.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_convtbc.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_utils.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_label_smoothing.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_average_checkpoints.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_dictionary.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_binaries.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_sequence_scorer.py -> build/lib.linux-x86_64-3.6/tests\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-3.6/fairseq/criterions\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-3.6/fairseq/data\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-3.6/fairseq/modules\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/lstm.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/fconv.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "copying fairseq/models/transformer.py -> build/lib.linux-x86_64-3.6/fairseq/models\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-3.6/fairseq/tasks\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/nag.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "copying fairseq/optim/adam.py -> build/lib.linux-x86_64-3.6/fairseq/optim\n",
            "creating build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-3.6/fairseq/optim/lr_scheduler\n",
            "running build_ext\n",
            "building 'fairseq.libbleu' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/fairseq\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib\n",
            "creating build/temp.linux-x86_64-3.6/fairseq/clib/libbleu\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fdebug-prefix-map=/build/python3.6-sXpGnM/python3.6-3.6.3=. -specs=/usr/share/dpkg/no-pie-compile.specs -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o -std=c++11\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fdebug-prefix-map=/build/python3.6-sXpGnM/python3.6-3.6.3=. -specs=/usr/share/dpkg/no-pie-compile.specs -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -std=c++11\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -specs=/usr/share/dpkg/no-pie-link.specs -Wl,-z,relro -Wl,-Bsymbolic-functions -specs=/usr/share/dpkg/no-pie-link.specs -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.6-sXpGnM/python3.6-3.6.3=. -specs=/usr/share/dpkg/no-pie-compile.specs -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-3.6/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so\n",
            "running develop\n",
            "running egg_info\n",
            "creating fairseq.egg-info\n",
            "writing fairseq.egg-info/PKG-INFO\n",
            "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
            "writing requirements to fairseq.egg-info/requires.txt\n",
            "writing top-level names to fairseq.egg-info/top_level.txt\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "reading manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.6/fairseq/libbleu.cpython-36m-x86_64-linux-gnu.so -> fairseq\n",
            "Creating /usr/local/lib/python3.6/dist-packages/fairseq.egg-link (link to .)\n",
            "Adding fairseq 0.5.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/fairseq\n",
            "Processing dependencies for fairseq==0.5.0\n",
            "Searching for tqdm==4.24.0\n",
            "Best match: tqdm 4.24.0\n",
            "Adding tqdm 4.24.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for torch==0.4.1\n",
            "Best match: torch 0.4.1\n",
            "Adding torch 0.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.14.5\n",
            "Best match: numpy 1.14.5\n",
            "Adding numpy 1.14.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cffi==1.11.5\n",
            "Best match: cffi 1.11.5\n",
            "Adding cffi 1.11.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pycparser==2.18\n",
            "Best match: pycparser 2.18\n",
            "Adding pycparser 2.18 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for fairseq==0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3u_dRkrJO9fC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "4yDn86nIs2cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2672
        },
        "outputId": "d7d4917e-a57d-4d00-bee2-5a04b9ad5496"
      },
      "cell_type": "code",
      "source": [
        "%cd examples/translation/\n",
        "!bash prepare-translit.sh\n",
        "%cd ../.."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fairseq/examples/translation\n",
            "Cloning Moses github repository (for tokenization scripts)...\n",
            "Cloning into 'mosesdecoder'...\n",
            "remote: Counting objects: 147104, done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 147104 (delta 0), reused 2 (delta 0), pack-reused 147098\u001b[K\n",
            "Receiving objects: 100% (147104/147104), 129.65 MiB | 21.17 MiB/s, done.\n",
            "Resolving deltas: 100% (113696/113696), done.\n",
            "Cloning Subword NMT repository (for BPE pre-processing)...\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Counting objects: 455, done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 455 (delta 18), reused 18 (delta 9), pack-reused 420\u001b[K\n",
            "Receiving objects: 100% (455/455), 204.70 KiB | 12.79 MiB/s, done.\n",
            "Resolving deltas: 100% (262/262), done.\n",
            "Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n",
            "--2018-08-16 11:18:05--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n",
            "Resolving wit3.fbk.eu (wit3.fbk.eu)... 217.77.80.8\n",
            "Connecting to wit3.fbk.eu (wit3.fbk.eu)|217.77.80.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19982877 (19M) [application/x-gzip]\n",
            "Saving to: ‘de-en.tgz’\n",
            "\n",
            "de-en.tgz           100%[===================>]  19.06M  5.58MB/s    in 4.4s    \n",
            "\n",
            "2018-08-16 11:18:10 (4.34 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\n",
            "\n",
            "Data successfully downloaded.\n",
            "de-en/\n",
            "de-en/IWSLT14.TED.dev2010.de-en.de.xml\n",
            "de-en/IWSLT14.TED.dev2010.de-en.en.xml\n",
            "de-en/IWSLT14.TED.tst2010.de-en.de.xml\n",
            "de-en/IWSLT14.TED.tst2010.de-en.en.xml\n",
            "de-en/IWSLT14.TED.tst2011.de-en.de.xml\n",
            "de-en/IWSLT14.TED.tst2011.de-en.en.xml\n",
            "de-en/IWSLT14.TED.tst2012.de-en.de.xml\n",
            "de-en/IWSLT14.TED.tst2012.de-en.en.xml\n",
            "de-en/IWSLT14.TEDX.dev2012.de-en.de.xml\n",
            "de-en/IWSLT14.TEDX.dev2012.de-en.en.xml\n",
            "de-en/README\n",
            "de-en/train.en\n",
            "de-en/train.tags.de-en.de\n",
            "de-en/train.tags.de-en.en\n",
            "pre-processing train data...\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "clean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n",
            "..........(100000).......\n",
            "Input sentences: 174443  Output sentences:  167497\n",
            "pre-processing valid/test data...\n",
            "orig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\n",
            "Tokenizer Version 1.1\n",
            "Language: de\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "orig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 8\n",
            "\n",
            "creating train, valid, test...\n",
            "learn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n",
            "subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "apply_bpe.py to train.de...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to valid.de...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to test.de...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to train.en...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to valid.en...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "apply_bpe.py to test.en...\n",
            "subword-nmt/apply_bpe.py:334: DeprecationWarning: this script's location has moved to /content/fairseq/examples/translation/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
            "  DeprecationWarning\n",
            "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
            "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
            "/content/fairseq\n",
            "Namespace(alignfile=None, destdir='data-bin/iwslt14.tokenized.de-en', joined_dictionary=False, nwordssrc=-1, nwordstgt=-1, only_source=False, output_format='binary', padding_factor=8, source_lang='de', srcdict=None, target_lang='en', testpref='examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, thresholdsrc=0, thresholdtgt=0, trainpref='examples/translation/iwslt14.tokenized.de-en/train', validpref='examples/translation/iwslt14.tokenized.de-en/valid')\n",
            "| [de] Dictionary: 127 types\n",
            "| [de] examples/translation/iwslt14.tokenized.de-en/train.de: 160215 sents, 19932043 tokens, 0.0% replaced by <unk>\n",
            "| [de] Dictionary: 127 types\n",
            "| [de] examples/translation/iwslt14.tokenized.de-en/valid.de: 7282 sents, 913474 tokens, 0.000219% replaced by <unk>\n",
            "| [de] Dictionary: 127 types\n",
            "| [de] examples/translation/iwslt14.tokenized.de-en/test.de: 6750 sents, 797914 tokens, 0.00589% replaced by <unk>\n",
            "| [en] Dictionary: 103 types\n",
            "| [en] examples/translation/iwslt14.tokenized.de-en/train.en: 160215 sents, 17967785 tokens, 0.0% replaced by <unk>\n",
            "| [en] Dictionary: 103 types\n",
            "| [en] examples/translation/iwslt14.tokenized.de-en/valid.en: 7282 sents, 823945 tokens, 0.0% replaced by <unk>\n",
            "| [en] Dictionary: 103 types\n",
            "| [en] examples/translation/iwslt14.tokenized.de-en/test.en: 6750 sents, 714703 tokens, 0.0007% replaced by <unk>\n",
            "| Wrote preprocessed data to data-bin/iwslt14.tokenized.de-en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eGVffTC7Srab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python preprocess.py --source-lang latn --target-lang armn \\\n",
        "  --trainpref examples/translation/translit.tokenized.latn-armn/train \\\n",
        "  --validpref examples/translation/translit.tokenized.latn-armn/valid \\\n",
        "  --testpref examples/translation/translit.tokenized.latn-armn/test \\\n",
        "  --destdir data-bin/translit.tokenized.latn-armn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AcNYbXT2O4Tc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "KZtPXjH5QJ__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "8115223e-e0fc-41b7-da25-8792c04e4a56"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p checkpoints/fconv\n",
        "!CUDA_VISIBLE_DEVICES=0 python train.py data-bin/translit.tokenized.latn-armn \\\n",
        "  --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 1024 \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --lr-scheduler fixed --force-anneal 200 \\\n",
        "  --arch fconv_translit_latn_armn --save-dir checkpoints/fconv \\\n",
        "  --skip-invalid-size-inputs-valid-test\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(arch='fconv_iwslt_de_en', clip_norm=0.1, criterion='label_smoothed_cross_entropy', data='data-bin/iwslt14.tokenized.de-en', decoder_attention='True', decoder_embed_dim=256, decoder_embed_path=None, decoder_layers='[(256, 3)] * 3', decoder_out_embed_dim=256, device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, encoder_embed_dim=256, encoder_embed_path=None, encoder_layers='[(256, 3)] * 4', force_anneal=200, fp16=False, keep_interval_updates=-1, label_smoothing=0.1, left_pad_source='True', left_pad_target='False', log_format=None, log_interval=1000, lr=[0.25], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=1024, max_update=0, min_loss_scale=0.0001, min_lr=1e-05, momentum=0.99, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, normalization_constant=0.5, optimizer='nag', raw_text=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/fconv', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, source_lang=None, target_lang=None, task='translation', train_subset='train', update_freq=[1], valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)\r\n",
            "| [de] dictionary: 128 types\r\n",
            "| [en] dictionary: 104 types\n",
            "| data-bin/iwslt14.tokenized.de-en train 160215 examples\n",
            "| data-bin/iwslt14.tokenized.de-en valid 7282 examples\n",
            "| model fconv_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\n",
            "| num. model params: 4030672\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = 1024 and max sentences per GPU = None\n",
            "| WARNING: 12 samples have invalid sizes and will be skipped, max_positions=(1022, 1022), first few sample ids=[141714, 139788, 109171, 130365, 130009, 44218, 153337, 65733, 14150, 82551]\n",
            "| loaded checkpoint checkpoints/fconv/checkpoint_last.pt (epoch 10 @ 63630 updates)\n",
            "| epoch 010:   3%| | 766/24201 [01:00<30:50, 12.67it/s, loss=2.259, nll_loss=1.325, ppl=2.51, wps=477, ups=0.6, wpb=751, bsz=7, num_updates=64396, lr=0.25, gnorm=0.126, clip=99%, oom=0, wall=7308]^C\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 347, in <module>\n",
            "    main(args)\n",
            "  File \"train.py\", line 87, in main\n",
            "    train(args, trainer, task, epoch_itr)\n",
            "  File \"train.py\", line 125, in train\n",
            "    log_output = trainer.train_step(sample, update_params=True)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 120, in train_step\n",
            "    oom_bwd = self._backward(loss)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 221, in _backward\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 93, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 90, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SAFrx--fPeNr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ]
    },
    {
      "metadata": {
        "id": "V0DVOzfePiYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python generate.py data-bin/translit.tokenized.latn-armn \\\n",
        "  --path checkpoints/fconv/checkpoint_best.pt \\\n",
        "  --batch-size 128 --beam 5 \\\n",
        "  --skip-invalid-size-inputs-valid-test"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
